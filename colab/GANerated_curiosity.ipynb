{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GANerated curiosity",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "cMZsJVOCBDLc",
        "SK2Dy4vRxupP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "cMZsJVOCBDLc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ]
    },
    {
      "metadata": {
        "id": "btJVe39dBIbS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Packages"
      ]
    },
    {
      "metadata": {
        "id": "P6udten7BGLz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Utils\n",
        "import numpy as np\n",
        "from pdb import set_trace\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# NN\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import gym\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TwoWlqXQBMwJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Constants"
      ]
    },
    {
      "metadata": {
        "id": "z7v6VL0M_3XZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BETA = .2\n",
        "LAMBDA = .1\n",
        "LR = 1e-1\n",
        "\n",
        "NUM_EPOCH = 10\n",
        "NUM_STEP = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SK2Dy4vRxupP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Models"
      ]
    },
    {
      "metadata": {
        "id": "Qr1xypJEx2od",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    \"\"\" 4 Conv2d + LeakyReLU \"\"\"\n",
        "    def __init__(self, ch_in=1):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        \n",
        "        # constants\n",
        "        self.num_filter = 32\n",
        "        self.size = 3\n",
        "        self.stride = 2\n",
        "        self.pad = self.size//2 \n",
        "\n",
        "        # layers\n",
        "        self.conv1 = nn.Conv2d(ch_in, self.num_filter, self.size, self.stride, self.pad)\n",
        "        self.conv2 = nn.Conv2d(self.num_filter, self.num_filter, self.size, self.stride, self.pad)\n",
        "        self.conv3 = nn.Conv2d(self.num_filter, self.num_filter, self.size, self.stride, self.pad)\n",
        "        self.conv4 = nn.Conv2d(self.num_filter, self.num_filter, self.size, self.stride, self.pad)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.conv1(x))\n",
        "        x = F.leaky_relu(self.conv2(x))\n",
        "        x = F.leaky_relu(self.conv3(x))\n",
        "        x = F.leaky_relu(self.conv4(x))\n",
        "\n",
        "        return torch.flatten(x)\n",
        "\n",
        "\n",
        "class FeatureEncoderNet(nn.Module):\n",
        "    \"\"\" Network for feature encoding\n",
        "\n",
        "        In: [s_t]\n",
        "            Current state (i.e. pixels) -> 1 channel image is needed\n",
        "\n",
        "        Out: phi(s_t)\n",
        "            Current state transformed into feature space\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, in_size, is_a3c=True):\n",
        "        super(FeatureEncoderNet, self).__init__()\n",
        "        # constants\n",
        "        self.in_size = in_size\n",
        "        self.h1 = 256\n",
        "        self.num_layers = 1\n",
        "        self.num_directions = 1\n",
        "        self.is_a3c = True # indicates whether the LSTM is needed\n",
        "\n",
        "        # layers\n",
        "        self.conv = ConvBlock()\n",
        "        if self.is_a3c:\n",
        "          self.lstm = nn.LSTM(input_size=self.in_size, hidden_size=self.h1, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #set_trace()\n",
        "        \n",
        "        if self.is_a3c:\n",
        "          h_t1 = c_t1 = torch.zeros(self.num_layers*self.num_directions, x.size(0), self.h1).cuda() if torch.cuda.is_available() else torch.zeros(self.num_layers*self.num_directions,x.size(0),self.h1)\n",
        "\n",
        "        x = self.conv(x)\n",
        "        \n",
        "        if self.is_a3c:\n",
        "          x = x.view(1,1,-1)\n",
        "          h_t1, c_t1 = self.lstm(x, (h_t1, c_t1)) # h_t1 is the output\n",
        "\n",
        "          return h_t1[:, -1, :]#.reshape(-1)\n",
        "        \n",
        "        else:\n",
        "          return x\n",
        "\n",
        "\n",
        "class InverseNet(nn.Module):\n",
        "    \"\"\" Network for the inverse dynamics\n",
        "\n",
        "        In: torch.cat((phi(s_t), phi(s_{t+1}), 1)\n",
        "            Current and next states transformed into the feature space, \n",
        "            denoted by phi().\n",
        "\n",
        "        Out: \\hat{a}_t\n",
        "            Predicted action\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, num_actions):\n",
        "        super(InverseNet, self).__init__()\n",
        "\n",
        "        # constants\n",
        "        #self.conv_out = 288\n",
        "        self.feat_size = 256\n",
        "        self.fc_hidden = 256\n",
        "        self.num_actions = num_actions\n",
        "\n",
        "        # layers\n",
        "        #self.conv = ConvBlock()\n",
        "        self.fc1 = nn.Linear(self.feat_size*2, self.fc_hidden)\n",
        "        self.fc2 = nn.Linear(self.fc_hidden, self.num_actions)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.fc1(x))\n",
        "\n",
        "\n",
        "class ForwardNet(nn.Module):\n",
        "    \"\"\" Network for the forward dynamics\n",
        "\n",
        "    In: torch.cat((phi(s_t), a_t), 1)\n",
        "        Current state transformed into the feature space, \n",
        "        denoted by phi() and current action\n",
        "\n",
        "    Out: \\hat{phi(s_{t+1})}\n",
        "        Predicted next state (in feature space)\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, in_size):\n",
        "\n",
        "        super(ForwardNet, self).__init__()\n",
        "\n",
        "        # constants\n",
        "        self.in_size = in_size\n",
        "        self.fc_hidden = 256\n",
        "        self.out_size = 256\n",
        "\n",
        "        # layers\n",
        "        self.fc1 = nn.Linear(self.in_size, self.fc_hidden)\n",
        "        self.fc2 = nn.Linear(self.fc_hidden, self.out_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #set_trace()\n",
        "        return self.fc2(self.fc1(x))\n",
        "\n",
        "\n",
        "class AdversarialHead(nn.Module):\n",
        "    def __init__(self, feat_size, num_actions):\n",
        "        super(AdversarialHead, self).__init__()\n",
        "\n",
        "        # constants\n",
        "        self.feat_size = feat_size\n",
        "        self.num_actions = num_actions\n",
        "\n",
        "        # networks\n",
        "        self.fwd_net = ForwardNet(self.feat_size + self.num_actions)\n",
        "        self.inv_net = InverseNet(num_actions)\n",
        "\n",
        "    def forward(self, phi_t, phi_t1, a_t):\n",
        "        \"\"\"\n",
        "            phi_t: current encoded state\n",
        "            phi_t1: next encoded state\n",
        "\n",
        "            a_t: current action\n",
        "        \"\"\"\n",
        "\n",
        "        # forward dynamics\n",
        "        # predict next encoded state\n",
        "        #set_trace()\n",
        "        fwd_in = torch.cat((phi_t, a_t), 1) # concatenate next to each other\n",
        "        phi_t1_hat =  self.fwd_net(fwd_in)\n",
        "\n",
        "        # inverse dynamics\n",
        "        # predict the action between s_t and s_t1\n",
        "        inv_in = torch.cat((phi_t, phi_t1), 1)\n",
        "        a_t_hat = self.inv_net(inv_in)\n",
        "\n",
        "\n",
        "        return phi_t1_hat, a_t_hat\n",
        "\n",
        "\n",
        "class ICMNet(nn.Module):\n",
        "    def __init__(self, num_actions, in_size=288, feat_size=256):\n",
        "        super(ICMNet, self).__init__()\n",
        "\n",
        "        # constants\n",
        "        self.in_size = in_size # pixels i.e. state\n",
        "        self.feat_size = feat_size\n",
        "        self.num_actions = num_actions\n",
        "\n",
        "        # networks\n",
        "        self.feat_enc_net = FeatureEncoderNet(self.in_size, is_a3c=False)\n",
        "        self.pred_net = AdversarialHead(self.feat_size, self.num_actions)     # goal: minimize prediction error \n",
        "        self.policy_net = AdversarialHead(self.feat_size, self.num_actions)   # goal: maximize prediction error \n",
        "                                                                            # (i.e. predict states which can contain new information)\n",
        "\n",
        "    def forward(self, s_t, s_t1, a_t):\n",
        "        \"\"\"\n",
        "            s_t : current state\n",
        "            s_t1: next state\n",
        "\n",
        "            phi_t: current encoded state\n",
        "            phi_t1: next encoded state\n",
        "\n",
        "            a_t: current action\n",
        "        \"\"\"\n",
        "\n",
        "        # encode the states\n",
        "        phi_t = self.feat_enc_net(s_t)\n",
        "        phi_t1 = self.feat_enc_net(s_t1)\n",
        "\n",
        "        # HERE COMES THE NEW THING (currently commented out)\n",
        "        phi_t1_pred, a_t_pred = self.pred_net(phi_t, phi_t1, a_t)\n",
        "        #phi_t1_policy, a_t_policy = self.policy_net_net(phi_t, phi_t1, a_t)\n",
        "\n",
        "\n",
        "        return phi_t1, phi_t1_pred, a_t_pred#(phi_t1_pred, a_t_pred), (phi_t1_policy, a_t_policy)\n",
        "\n",
        "\n",
        "class A3CNet(nn.Module):\n",
        "    def __init__(self, num_actions, in_size=288):\n",
        "        super(A3CNet, self).__init__()\n",
        "\n",
        "        # constants\n",
        "        self.in_size = in_size\n",
        "        self.num_actions = num_actions\n",
        "\n",
        "        # networks\n",
        "        self.feat_enc_net = FeatureEncoderNet(self.in_size)\n",
        "        self.actor = nn.Linear(self.feat_enc_net.h1, self.num_actions) # estimates what to do\n",
        "        self.critic = nn.Linear(self.feat_enc_net.h1, 1) # estimates how good the value function (how good the current state is)\n",
        "\n",
        "    def forward(self, s_t):\n",
        "        \"\"\"\n",
        "            s_t : current state\n",
        "           \n",
        "            phi_t: current encoded state\n",
        "        \"\"\"\n",
        "        phi_t = self.feat_enc_net(s_t)\n",
        "\n",
        "        policy = self.actor(phi_t)\n",
        "        value = self.critic(phi_t)\n",
        "\n",
        "        return policy, value\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IZbgJs5gyBSD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Agent"
      ]
    },
    {
      "metadata": {
        "id": "EHOlhMfZyOSa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ICMAgent(nn.Module):\n",
        "    def __init__(self, num_actions, in_size=288):\n",
        "        super().__init__()\n",
        "\n",
        "        # constants\n",
        "        self.in_size = in_size\n",
        "        self.num_actions = num_actions\n",
        "        self.is_cuda = torch.cuda.is_available()\n",
        "        \n",
        "        self.cum_r = 0\n",
        "\n",
        "        # networks\n",
        "        self.icm = ICMNet(self.num_actions, self.in_size)\n",
        "        self.a3c = A3CNet(self.num_actions, self.in_size)\n",
        "\n",
        "        if self.is_cuda:\n",
        "            self.icm.cuda()\n",
        "            self.a3c.cuda()\n",
        "\n",
        "        # optimizer\n",
        "        self.optimizer = optim.Adam( list(self.icm.parameters()) + list(self.a3c.parameters()) )\n",
        "\n",
        "    def get_action(self, s_t):\n",
        "        #s_t = torch.Tensor(s_t).float()  # copy state to device as float\n",
        "        #s_t = s_t.float()\n",
        "        #s_t = self.pix2tensor(s_t)\n",
        "        policy, value = self.a3c(s_t) # use A3C to get policy and value\n",
        "        action_prob = F.softmax(policy, dim=-1).data.cpu().numpy()\n",
        "        #action_prob = action_prob[0,:,:] #remove first dimension\n",
        "        a_t = self.sel_rnd_idx(action_prob) # detach for action?\n",
        "\n",
        "        return a_t, value.data.cpu().numpy().squeeze(), policy.detach()\n",
        "\n",
        "    @staticmethod\n",
        "    def sel_rnd_idx(p, axis=1):\n",
        "        r = np.expand_dims(np.random.rand(p.shape[1 - axis]), axis=axis) # insert a new dim with a random value\n",
        "        return (p.cumsum(axis=axis) > r).argmax(axis=axis)\n",
        "\n",
        "    def cumulate_reward(self, r):\n",
        "        self.cum_r += r\n",
        "        return self.cum_r\n",
        "\n",
        "    # functions\n",
        "    def pix2tensor(self, pix):\n",
        "        im2tensor = transforms.Compose([transforms.ToPILImage(),\n",
        "                                        transforms.Grayscale(1),\n",
        "                                        transforms.Resize((42,42)),\n",
        "                                        transforms.ToTensor()])\n",
        "\n",
        "        return torch.unsqueeze(im2tensor(pix),0).cuda()\n",
        "\n",
        "    def train(self, env_name, num_epoch, num_steps):\n",
        "        \"\"\"\n",
        "            s_t : current state\n",
        "            s_t1: next state\n",
        "\n",
        "            phi_t: current encoded state\n",
        "            phi_t1: next encoded state\n",
        "\n",
        "            a_t: current action\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "        env = gym.make(env_name)\n",
        "\n",
        "        \"\"\"for i in epoch\n",
        "        \n",
        "        calculate reduced extrinsic + (phi_t1_hat-phi_t1)^2 + categorical(a_t, a_t_hat)\n",
        "        maintain running statistics all of them\n",
        "\n",
        "        sample action space\n",
        "        \n",
        "        \"\"\"\n",
        "\n",
        "        for epoch in range(num_epoch):\n",
        "            s_t  = env.reset()\n",
        "            s_t = self.pix2tensor(s_t)\n",
        "\n",
        "            for step in range(num_steps):\n",
        "                from pdb import set_trace\n",
        "                #set_trace()\n",
        "                \n",
        "                a_t, policy, value = self.get_action(s_t) # select action from the policy\n",
        "\n",
        "                # interact with the environment\n",
        "                s_t1, r, done, info = env.step(a_t)\n",
        "                r_cum = self.cumulate_reward(r)\n",
        "                s_t1 = self.pix2tensor(s_t1)\n",
        "\n",
        "                # call the ICM model\n",
        "                a_t = torch.FloatTensor(a_t)\n",
        "                a_t_1_hot = torch.zeros(1,self.num_actions).scatter_(1, a_t.long().view(-1,1),1)\n",
        "                if self.is_cuda:\n",
        "                    a_t = a_t.cuda()\n",
        "                    a_t_1_hot = a_t_1_hot.cuda()\n",
        "                \n",
        "                phi_t1, phi_t1_pred, a_t_pred = self.icm(s_t, s_t1, a_t_1_hot)\n",
        "\n",
        "\n",
        "                # calculate losses\n",
        "                loss_int = F.mse_loss(phi_t1_pred, phi_t1)\n",
        "                loss_inv = F.cross_entropy(a_t_pred, a_t.long())\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                # compose losses\n",
        "                loss = BETA*loss_int + (1-BETA)*loss_inv - LAMBDA*r_cum\n",
        "\n",
        "                print(\"Epoch: {}, step: {}, loss {}\".format(epoch, step, loss) )\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "                s_t = s_t1 # the current next state will be the new current state \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qjflexYKyT_T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train"
      ]
    },
    {
      "metadata": {
        "id": "01aK3DKAyO0O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# objects\n",
        "env = gym.make('MsPacman-v0')\n",
        "#env = gym.make('MontezumaRevenge-v0')\n",
        "agent = ICMAgent(env.action_space.n)\n",
        "\n",
        "agent.cuda()\n",
        "agent.train('MontezumaRevenge-v0', NUM_EPOCH, NUM_STEP)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gjnf5T5BAgjZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}